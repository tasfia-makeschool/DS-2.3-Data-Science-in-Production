{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker and AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Docker? \n",
    "- Docker is a container management service \n",
    "- The keywords of Docker are `develop`, `ship`, and `run`. \n",
    "- It provides tools for simplifying DevOps \n",
    "    - images are templates for lightweight virtual machines\n",
    "    - containers are instances of an image or images\n",
    "        - applications and it's dependencies run here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we deploy a ML or DL model on the cloud (AWS)? \n",
    "1. Train, evaluate, and save the model (pickle for ML, h5 (Hadoop) for DL)\n",
    "2. Build a Flask API for the model \n",
    "3. Create a `Dockerfile` and dockerize and test the Flask API on our machine \n",
    "4. Build container and deploy to AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Build a NN for MNIST \n",
    "1. Train a DL model for MNIST dataset (MLP or CNN)\n",
    "2. Save model as h5\n",
    "3. Test model by passing in an image from the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Dropout, Flatten # MLP\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape\t (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"input shape\\t\", input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.058524837224162185\n",
      "Test accuracy: 0.9803\n"
     ]
    }
   ],
   "source": [
    "# measure accuracy of model\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[3.1880464e-08 5.4522009e-09 2.9700420e-06 1.8667237e-07 6.3274358e-10\n",
      " 2.8115728e-09 5.1061278e-12 9.9999619e-01 8.0669537e-08 4.9990240e-07]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])\n",
    "x = X_test[0].reshape(1, 28, 28, 1)\n",
    "out = model.predict(x)\n",
    "print(out[0])\n",
    "print(np.argmax(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('model.h5')\n",
    "\n",
    "# Save the weights\n",
    "model.save_weights('model_weights.h5')\n",
    "\n",
    "# Save the model architecture\n",
    "with open('model_architecture.json', 'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13daf2f10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = Image.open(\"test_mnist_6.jpg\")\n",
    "img_arr = np.array(img)\n",
    "plt.imshow(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "x = img_arr.reshape(1, 28, 28, 1)\n",
    "output = model.predict(x)\n",
    "print(output[0])\n",
    "print(np.argmax(output[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "class_virtual_env",
   "language": "python",
   "name": "class_virtual_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
